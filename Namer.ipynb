{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuzF7xPkhHgBA1booOGIf/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iyxlBeETUCvQ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.optim as optim\n"]},{"cell_type":"markdown","source":["# Download data"],"metadata":{"id":"LK2yjFlOUQ3G"}},{"cell_type":"code","source":["!wget -q https://www.ssa.gov/oact/babynames/names.zip\n","!unzip -q names.zip"],"metadata":{"collapsed":true,"id":"xZwUtKJkUSNk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["names_path = \"/content/yob2023.txt\"\n","\n","names = []\n","with open(names_path) as file:\n","  for line in file:\n","    name, _, _ = line.lower().strip().split(',')\n","    names.append(\"$\" + name + \"$\") # $ is used for start and end tokens\n","\n","print(f\"{len(names)} names retrieved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ub2CwIoFUQBL","executionInfo":{"status":"ok","timestamp":1724589284441,"user_tz":-180,"elapsed":14,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"3669d990-d1f1-4c7f-aec0-ce923aadc008"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["31682 names retrieved\n"]}]},{"cell_type":"markdown","source":["# Bigram Model"],"metadata":{"id":"xqqZMEcOVfh0"}},{"cell_type":"code","source":["vocab = \"$abcdefghijklmnopqrstuvwxyz\"\n","vocab_size = len(vocab)\n","\n","# Create two dicts for encoding and decoding\n","char_to_index = {char: i for i, char in enumerate(vocab)}\n","index_to_char = {i: char for i, char in enumerate(vocab)}"],"metadata":{"id":"N0lHSG93V3fs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bigram is a 2D matrix of probabilities (ab, ac, etc.)\n","\n","bigram = torch.zeros((vocab_size, vocab_size))\n","total = 0\n","for name in names:\n","  for ch1, ch2 in zip(name, name[1:]):\n","    ch1_idx = char_to_index[ch1]\n","    ch2_idx = char_to_index[ch2]\n","    bigram[ch1_idx][ch2_idx] += 1\n","    total += 1\n","bigram /= total\n"],"metadata":{"id":"dGQlhuw7Vgvj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample characters given probabilities\n","def gaussian_sampler(bigram_probs):\n","  generated = \"$\"\n","  while True:\n","    bigram_probs = bigram[char_to_index[generated[-1]]]\n","    sampled_char = index_to_char[\n","        torch.multinomial(bigram_probs, 1).item()\n","    ]\n","    if sampled_char == \"$\":\n","      break\n","    generated += sampled_char\n","  return generated[1:]\n","\n","for i in range(5):\n","  print(f\"name {i+1}: {gaussian_sampler(bigram)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kf5iT4TVW3xy","executionInfo":{"status":"ok","timestamp":1724589291211,"user_tz":-180,"elapsed":24,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"beefa18f-5eb5-4ea2-dca7-f237e8ca475e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["name 1: can\n","name 2: laves\n","name 3: ly\n","name 4: bry\n","name 5: a\n"]}]},{"cell_type":"markdown","source":["Utility functions"],"metadata":{"id":"ZBM94rxOYnv-"}},{"cell_type":"code","source":["def encode(word):\n","  indices = [char_to_index[char] for char in word]\n","  return torch.tensor(indices)\n","\n","\n","def decode(indices_tensor):\n","  indices_char = [index_to_char[i.item()] for i in indices_tensor]\n","  name = ''.join(indices_char)\n","  return name\n","\n","example_name = \"$ada$\"\n","encoded_name = encode(example_name)\n","decoded_name = decode(encoded_name)\n","print(encoded_name)\n","print(decoded_name)\n","\n","assert example_name == decoded_name, \"Encoder or Decoder implemented incorrectly\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWqzemGzYWUy","executionInfo":{"status":"ok","timestamp":1724589291211,"user_tz":-180,"elapsed":20,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"1875dfa9-92f8-4b27-ea91-74b355260ce5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 1, 4, 1, 0])\n","$ada$\n"]}]},{"cell_type":"markdown","source":["### Padding"],"metadata":{"id":"5kyx77M3rFgi"}},{"cell_type":"code","source":["name_indices = [encode(name) for name in names] # $...$\n","target_indices = [name_index[1:] for name_index in name_indices] # ...$\n","\n","max_name_length = max(len(name) for name in names)\n","\n","X = pad_sequence(name_indices, batch_first=True, padding_value=0) # extend with 0 to match the max_len for each name\n","target_indices.append(torch.empty((max_name_length), dtype=torch.long)) # in case max_len was not in target_indices append an empty name\n","Y = pad_sequence(target_indices, batch_first=True, padding_value=-1)[:-1] # remove the empty name after the padding was done\n","                                                                          # also extend by -1 to match the max_len\n","                                                                          # the model ignores -1 (no loss update)\n","\n","print(X[0])\n","print(Y[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-27VbQv-bvn8","executionInfo":{"status":"ok","timestamp":1724589292228,"user_tz":-180,"elapsed":1033,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"e5dac64c-c9c5-4415-e6a3-50ff90571989"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0, 15, 12,  9, 22,  9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n","tensor([15, 12,  9, 22,  9,  1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n"]}]},{"cell_type":"code","source":["def get_batch(batch_size=64):\n","  random_idx = torch.randint(0, X.size(0), (batch_size,))\n","  inputs = X[random_idx]\n","  labels = Y[random_idx]\n","  return inputs, labels\n","\n","inputs, labels = get_batch(3)\n","print(inputs)\n","print(labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsJJ8rvPfcsW","executionInfo":{"status":"ok","timestamp":1724589292229,"user_tz":-180,"elapsed":10,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"5b8f0f34-fdb2-4d3d-a1ab-d0595808e9fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0, 11,  9, 18,  9,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0,  2, 18,  5, 24, 20, 15, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0,  1, 13,  1, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n","tensor([[11,  9, 18,  9,  5,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n","        [ 2, 18,  5, 24, 20, 15, 14,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n","        [ 1, 13,  1, 18,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])\n"]}]},{"cell_type":"markdown","source":["### Embedding"],"metadata":{"id":"cbYxor5DrIJt"}},{"cell_type":"code","source":["embedding_dim = 3\n","embedding = nn.Embedding(vocab_size, embedding_dim)\n","\n","example_input = torch.tensor([[1, 1, 0, 2], [2, 1, 2, 4]])\n","input_embd = embedding(example_input)\n","print(input_embd.shape)\n","input_embd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59TEpKPaqoLP","executionInfo":{"status":"ok","timestamp":1724589292229,"user_tz":-180,"elapsed":7,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"41f3386f-29de-4abc-863b-f0fe38b39a33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 4, 3])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.7031,  0.0419, -0.0223],\n","         [ 0.7031,  0.0419, -0.0223],\n","         [ 0.1891,  0.8083,  1.4786],\n","         [-0.5859,  0.9281,  1.5602]],\n","\n","        [[-0.5859,  0.9281,  1.5602],\n","         [ 0.7031,  0.0419, -0.0223],\n","         [-0.5859,  0.9281,  1.5602],\n","         [ 1.4030, -0.7524,  0.7533]]], grad_fn=<EmbeddingBackward0>)"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# A Simple Deep Neural Network"],"metadata":{"id":"bQMPVFrxrpwP"}},{"cell_type":"code","source":["class SequenceMLP(nn.Module):\n","  def __init__(self, vocab_size, max_sequence_length, embedding_dim, hidden_dim=32):\n","    super().__init__()\n","    self.vocab_size = vocab_size\n","    self.max_sequence_length = max_sequence_length\n","    self.embedding_dim = embedding_dim\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    self.linear = nn.Linear(embedding_dim * max_sequence_length, hidden_dim)\n","    self.relu = nn.ReLU()\n","    self.out = nn.Linear(hidden_dim, vocab_size)\n","\n","  def forward(self, x):\n","    batch_size, seq_len = x.shape\n","    sequence_embeddings = torch.zeros(batch_size, seq_len, self.max_sequence_length * self.embedding_dim) # batch_size x current_word_len x (longest_word_we_want * 3)\n","    for i in range(seq_len):\n","      subsequence = torch.zeros(batch_size, self.max_sequence_length, dtype=torch.int)\n","      prefix = x[:, :i+1] # part of name [0:i+1] for each name in batch\n","      subsequence[:, :i+1] = prefix\n","      emb = self.embedding(subsequence)\n","      sequence_embeddings[:, i, :] = emb.view(batch_size, -1)\n","    x = self.linear(sequence_embeddings)\n","    x = nn.Linear(128, 256)(x)\n","    x = nn.Linear(256, 128)(x)\n","    x = self.relu(x)\n","    x = self.out(x)\n","    return x\n"],"metadata":{"id":"2tOxzbfQrt_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, optimizer, num_steps=10000, loss_report_interval=1000):\n","  losses = []\n","  for i in range(1, num_steps):\n","    inputs, labels = get_batch()\n","    optimizer.zero_grad()\n","    logits = model(inputs)\n","    loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), labels.view(-1), ignore_index=-1) # Ignore padding -1 from target\n","    losses.append(loss.item())\n","\n","    if i % loss_report_interval == 0:\n","      print(f\"Average loss at step {i+1}: {sum(losses[-loss_report_interval:]) / loss_report_interval:.4f}\")\n","\n","    loss.backward()\n","    optimizer.step()"],"metadata":{"id":"IwXqgPbzzC2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 3\n","max_sequence_length = X.shape[1]\n","model = SequenceMLP(vocab_size, max_sequence_length, embedding_dim, hidden_dim=128)\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","train(model, optimizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIboiXMr1Z7O","outputId":"d144947c-62fa-4631-a4d4-79d8bc2e906e","executionInfo":{"status":"ok","timestamp":1724589488226,"user_tz":-180,"elapsed":195571,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average loss at step 1001: 3.0485\n","Average loss at step 2001: 2.8698\n","Average loss at step 3001: 2.8460\n","Average loss at step 4001: 2.8370\n","Average loss at step 5001: 2.8340\n","Average loss at step 6001: 2.8276\n","Average loss at step 7001: 2.8216\n","Average loss at step 8001: 2.8150\n","Average loss at step 9001: 2.8058\n"]}]},{"cell_type":"code","source":["def generate_samples(model, num_samples=1, max_len=max_name_length):\n","  sequences = torch.zeros((num_samples, 1)).int()\n","  for _ in range(max_len):\n","    logits = model(sequences)\n","    logits = logits[:, -1, :]\n","    probs = F.softmax(logits, dim=-1)\n","    idx_next = torch.multinomial(probs, num_samples=1)\n","    sequences = torch.cat((sequences, idx_next), dim=1)\n","\n","  for sequence in sequences:\n","    indices = torch.where(sequence == 0)[0]\n","    end = indices[1] if len(indices) > 1 else max_len\n","    sequence = sequence[1:end]\n","    print(decode(sequence))\n","\n","generate_samples(model, num_samples=10)"],"metadata":{"id":"rPQJxTKU7iQX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724589488228,"user_tz":-180,"elapsed":24,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"94f93e0b-9c54-44fd-a91e-bcd7cf9edd7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tkes\n","a\n","\n","aainj\n","tlkary\n","\n","llwynyy\n","kdpivora\n","niorslisawwe\n","ahebk\n"]}]},{"cell_type":"markdown","source":["# Attention Namer"],"metadata":{"id":"NqaPNs59mztv"}},{"cell_type":"code","source":["class AttentionMLP(nn.Module):\n","  def __init__(self, n_embd, vocab_size, block_size, n_hidden=64):\n","    super().__init__()\n","    self.tok_embd = nn.Embedding(vocab_size, n_embd)\n","    self.attn_weights = None\n","\n","    self.query_proj = nn.Linear(n_embd, n_embd)\n","    self.key_proj = nn.Linear(n_embd, n_embd)\n","    self.value_proj = nn.Linear(n_embd, n_embd)\n","\n","    self.register_buffer(\"mask\", torch.tril(torch.ones((block_size, block_size)), diagonal=0)) # Not parameter\n","\n","    self.mlp = nn.Sequential(\n","        nn.Linear(n_embd, n_hidden),\n","        nn.ReLU(),\n","        nn.Linear(n_hidden, n_embd)\n","    )\n","\n","    self.output_proj = nn.Linear(n_embd, vocab_size)\n","\n","\n","  def forward(self, x):\n","    x = self.tok_embd(x)\n","    batch_size, seq_len, embd_dim = x.shape\n","\n","    q = self.query_proj(x)\n","    k = self.key_proj(x)\n","    v = self.value_proj(x)\n","\n","    attn_weights = q @ k.transpose(1, 2)\n","    attn_weights = attn_weights.masked_fill(self.mask[:seq_len, :seq_len] == 0, value=float('-inf'))\n","    attn_weights = attn_weights / torch.sqrt(torch.tensor(k.shape[-1]).float())\n","    self.attn_weights = F.softmax(attn_weights, dim=-1)\n","    x = self.attn_weights @ v\n","    x = self.mlp(x)\n","\n","    x = self.output_proj(x)\n","    return x"],"metadata":{"id":"4fgbQqKymzCW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AttentionMLP(32, vocab_size, max_name_length)\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","train(model, optimizer, num_steps=10_001, loss_report_interval=1_000)"],"metadata":{"id":"q7wtMS7yApp5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724589563176,"user_tz":-180,"elapsed":47386,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"69943b5c-15df-475d-d6a1-45c553e528a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average loss at step 1001: 2.9397\n","Average loss at step 2001: 2.6714\n","Average loss at step 3001: 2.6117\n","Average loss at step 4001: 2.5923\n","Average loss at step 5001: 2.5735\n","Average loss at step 6001: 2.5541\n","Average loss at step 7001: 2.5230\n","Average loss at step 8001: 2.4802\n","Average loss at step 9001: 2.4489\n","Average loss at step 10001: 2.4314\n"]}]},{"cell_type":"code","source":["generate_samples(model, 10)"],"metadata":{"id":"a89K-8TeAtHP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724589563176,"user_tz":-180,"elapsed":18,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"8e8a4acb-372a-456b-f7cf-943a5f48a708"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["disauni\n","pdihyu\n","dacad\n","rsakuu\n","kaver\n","zanr\n","parria\n","ziie\n","umliinh\n","haerao\n"]}]},{"cell_type":"markdown","source":["# Attention Transformer\n"],"metadata":{"id":"GSczqDcyebHe"}},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","  def __init__(self, n_embd, num_heads=4, n_hidden=64):\n","    super().__init__()\n","    assert n_embd % num_heads == 0, \"Embedding dimension must be divisible by the number of heads\"\n","\n","    self.num_heads = num_heads\n","    self.head_dim = n_embd // num_heads\n","\n","    self.query_proj = nn.Linear(n_embd, n_embd)\n","    self.key_proj = nn.Linear(n_embd, n_embd)\n","    self.value_proj = nn.Linear(n_embd, n_embd)\n","\n","    self.mlp = nn.Sequential(\n","        nn.Linear(n_embd, n_hidden),\n","        nn.ReLU(),\n","        nn.Linear(n_hidden, n_embd)\n","    )\n","\n","    # Layernorms\n","    self.norm_1 = nn.LayerNorm(n_embd)\n","    self.norm_2 = nn.LayerNorm(n_embd)\n","\n","  def forward(self, x):\n","    batch_size, sequence_length, _ = x.shape\n","\n","    q = self.query_proj(x)\n","    k = self.key_proj(x)\n","    v = self.value_proj(x)\n","\n","    # multihead attention\n","    q = q.view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n","    k = k.view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n","    v = v.view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","    # attention\n","    attended_v = F.scaled_dot_product_attention(q, k, v, is_causal=True)  # personally feel like calling the final output weights is wrong\n","\n","    # multiple head concatenation\n","    attended_v = attended_v.transpose(1, 2).contiguous().view(batch_size, sequence_length, -1)\n","\n","    # norm and residual connections\n","    x = self.norm_1(x + attended_v)\n","    x = self.norm_2(x + self.mlp(x))\n","    return x"],"metadata":{"id":"LT-oN51XecGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Transformer(nn.Module):\n","  def __init__(self, n_embd, vocab_size, block_size, num_blocks=6):\n","    super().__init__()\n","    self.char_embedding = nn.Embedding(vocab_size, n_embd)\n","    self.positional_embedding = nn.Embedding(block_size, n_embd)\n","\n","    self.transformer_blocks = nn.Sequential(\n","        *[TransformerBlock(n_embd) for _ in range(num_blocks)]\n","    )\n","\n","    self.output_proj = nn.Linear(n_embd, vocab_size)\n","\n","  def forward(self, x):\n","    _, seq_len = x.shape\n","\n","    pos_embd = self.positional_embedding(torch.arange(seq_len))\n","    char_embd = self.char_embedding(x)\n","    x = char_embd + pos_embd\n","    x = self.transformer_blocks(x)\n","    x = self.output_proj(x)\n","\n","    return x"],"metadata":{"id":"wEiV6cqGgyMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_embd = 64\n","model = Transformer(n_embd, vocab_size, block_size=max_name_length)\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","train(model, optimizer, num_steps=10_001, loss_report_interval=1_000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_iSNpF_hove","executionInfo":{"status":"ok","timestamp":1724590090213,"user_tz":-180,"elapsed":527050,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"1426cf89-4a72-4e6c-803f-14b94e8410f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average loss at step 1001: 2.2994\n","Average loss at step 2001: 2.1621\n","Average loss at step 3001: 2.1104\n","Average loss at step 4001: 2.0712\n","Average loss at step 5001: 2.0407\n","Average loss at step 6001: 2.0196\n","Average loss at step 7001: 1.9930\n","Average loss at step 8001: 1.9708\n","Average loss at step 9001: 1.9527\n","Average loss at step 10001: 1.9338\n"]}]},{"cell_type":"code","source":["generate_samples(model,num_samples=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5xX-xbYisfs","executionInfo":{"status":"ok","timestamp":1724590090213,"user_tz":-180,"elapsed":25,"user":{"displayName":"SABYR BAZARYMBETOV","userId":"14868025410305032615"}},"outputId":"ee320666-1245-4944-f63d-83c258d33615"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["elizara\n","ahmari\n","samaykei\n","ahnabett\n","hunton\n","seraya\n","machi\n","taulins\n","hode\n","wilmon\n"]}]}]}